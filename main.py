import os
import json
import csv
import time
import requests
from datetime import datetime
from tqdm import tqdm

# Import our modules
try:
    from embedder import VNPTEmbedder
    from rag_system import RAGSystem
    print("‚úì Successfully imported RAG modules")
except ImportError as e:
    print(f"‚úó Failed to import modules: {e}")
    print("Please ensure embedder.py and rag_system.py are in the same directory")
    exit(1)

# =========================================================
# CONFIGURATION
# =========================================================
CONFIG = {
    'api_keys_file': 'api-keys.json',
    'data_path': './src/data/test.json',
    'output_path': 'submission.csv',
    'use_rag': True,
    'max_requests_per_hour': 60,
    'max_requests_per_day': 1000,
    'request_delay': 1.0,
    'rag_top_k': 2,
    'max_context_length': 600,
    'max_retries': 3,
    'timeout': 30
}

# =========================================================
# LOAD API KEYS
# =========================================================
print("Loading API keys...")
with open(CONFIG['api_keys_file'], 'r', encoding='utf-8') as f:
    api_keys = json.load(f)

# Get VNPT AI API keys (the small model)
llm_small = api_keys[2]  # According to your working code
AUTHORIZATION = llm_small["authorization"]
TOKEN_KEY = llm_small["tokenKey"]
TOKEN_ID = llm_small["tokenId"]
API_URL = "https://api.idg.vnpt.vn/data-service/v1/chat/completions/vnptai-hackathon-small"

print("‚úì VNPT AI API keys loaded")

# =========================================================
# INITIALIZE RAG SYSTEM
# =========================================================
rag_system = None
if CONFIG['use_rag']:
    print("\n" + "="*50)
    print("Initializing RAG system...")
    print("="*50)
    
    try:
        # Check if FAISS index exists
        if not os.path.exists("faiss_index.bin") or not os.path.exists("metadata.json"):
            print("‚ö†Ô∏è FAISS index not found. RAG will be disabled.")
            print("   Run 'python faiss_index.py' to build the index first.")
            CONFIG['use_rag'] = False
        else:
            rag_system = RAGSystem(CONFIG['api_keys_file'])
            
            # Test embedding connection first
            if rag_system.embedder:
                print("\nTesting embedding API connection...")
                if not rag_system.embedder.test_connection():
                    print("\n‚ùå Embedding API test failed.")
                    choice = input("Continue without RAG? (y/n): ").strip().lower()
                    if choice == 'y':
                        CONFIG['use_rag'] = False
                    else:
                        exit(1)
                else:
                    print("‚úì Embedding API is working")
            
            if CONFIG['use_rag']:
                if rag_system.load_index():
                    print("\n‚úÖ RAG system ready")
                    print(f"   Documents in index: {rag_system.index.ntotal}")
                    
                    # Show initial usage
                    if rag_system.embedder:
                        usage = rag_system.embedder.get_usage()
                        print(f"   Embedding API usage: {usage['used']}/{usage['total']}")
                else:
                    print("‚ùå Failed to load RAG index")
                    CONFIG['use_rag'] = False
                    
    except Exception as e:
        print(f"\n‚úó RAG initialization failed: {e}")
        CONFIG['use_rag'] = False
else:
    print("‚ÑπÔ∏è RAG disabled by configuration")

print("\n" + "="*50)
print(f"Final Configuration:")
print(f"  RAG Enabled: {CONFIG['use_rag']}")
print(f"  VNPT AI Model: vnptai_hackathon_small")
print(f"  Max Requests: {CONFIG['max_requests_per_hour']}/hour, {CONFIG['max_requests_per_day']}/day")
print(f"  Output File: {CONFIG['output_path']}")
print("="*50 + "\n")

# =========================================================
# LOAD DATASET
# =========================================================
print(f"Loading dataset from {CONFIG['data_path']}...")
try:
    with open(CONFIG['data_path'], 'r', encoding="utf-8") as f:
        dataset = json.load(f)
    print(f"‚úì Loaded {len(dataset)} questions")
except Exception as e:
    print(f"‚úó Failed to load dataset: {e}")
    exit(1)

# =========================================================
# API CALL FUNCTION WITH RETRY
# =========================================================
def call_api_with_retry(payload, max_retries=3):
    """Call VNPT AI API with retry logic"""
    headers = {
        "Authorization": AUTHORIZATION,
        "Token-id": TOKEN_ID,
        "Token-key": TOKEN_KEY,
        "Content-Type": "application/json",
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                API_URL, 
                headers=headers, 
                json=payload, 
                timeout=CONFIG['timeout']
            )

            if response.status_code == 200:
                return response.json()

            # Handle rate limiting
            if response.status_code == 429:
                wait = 2 ** attempt
                print(f"   ‚ö†Ô∏è Rate limited, waiting {wait}s...")
                time.sleep(wait)
                continue
                
            print(f"   ‚ùå API error {response.status_code}: {response.text}")
            
            # For 401 errors, skip retry as it's an auth issue
            if response.status_code == 401:
                print("   ‚ùå Authentication failed. Check your API keys.")
                return None
                
            time.sleep(1)  # Small delay before retry

        except Exception as e:
            print(f"   ‚ö†Ô∏è Request error: {e}")
            time.sleep(1)
    
    return None

# =========================================================
# PREDICTION FUNCTION
# =========================================================
def predict_answer(question, choices):
    """Predict answer using RAG (if available) and VNPT AI"""
    
    # Step 1: Get RAG context
    context = ""
    if CONFIG['use_rag'] and rag_system and rag_system.embedder:
        try:
            print("   üîç Retrieving relevant information from knowledge base...")
            
            # Generate embedding for the question
            query_embedding = rag_system.embedder.encode(question)
            
            # Retrieve similar documents
            results = rag_system.retrieve(query_embedding, k=CONFIG['rag_top_k'])
            
            if results:
                # Format context
                context_lines = []
                for i, res in enumerate(results, 1):
                    text = res['text']
                    score = res.get('score', 0)
                    # Truncate if too long
                    if len(text) > 200:
                        # Try to cut at sentence boundary
                        if '.' in text[:250]:
                            cutoff = text[:250].rfind('.') + 1
                            text = text[:cutoff] + ".."
                        else:
                            text = text[:200] + "..."
                    
                    context_lines.append(f"[Source {i}, relevance: {1-score:.2f}] {text}")
                
                context = "\n".join(context_lines)
                print(f"   üìö Found {len(results)} relevant documents")
                
                # Show embedding usage
                if rag_system.embedder:
                    usage = rag_system.embedder.get_usage()
                    print(f"   üìä Embedding API usage: {usage['used']}/{usage['total']}")
            else:
                print("   ‚ÑπÔ∏è No relevant documents found in knowledge base")
        
        except Exception as e:
            print(f"   ‚ö†Ô∏è RAG error: {e}")
    
    # Step 2: Prepare payload for VNPT AI
    if context:
        # system_content = f"""B·∫°n l√† tr·ª£ l√Ω AI tr·∫£ l·ªùi c√¢u h·ªèi tr·∫Øc nghi·ªám ti·∫øng Vi·ªát.

# TH√îNG TIN THAM KH·∫¢O T·ª™ C∆† S·ªû KI·∫æN TH·ª®C:
# {context}

# H∆Ø·ªöNG D·∫™N:
# 1. ƒê·ªçc k·ªπ c√¢u h·ªèi v√† t·∫•t c·∫£ l·ª±a ch·ªçn
# 2. TR·∫¢ L·ªúI CH·ªà B·∫∞NG M·ªòT K√ù T·ª∞: A, B, C, D,....
# 3. KH√îNG gi·∫£i th√≠ch, KH√îNG th√™m vƒÉn b·∫£n
# 4. N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y ch·ªçn ƒë√°p √°n h·ª£p l√Ω nh·∫•t"""
        system_content = f"""
B·∫°n l√† AI chuy√™n tr·∫£ l·ªùi c√¢u h·ªèi tr·∫Øc nghi·ªám ti·∫øng Vi·ªát v·ªõi ƒë·ªô ch√≠nh x√°c cao.

NGU·ªíN DUY NH·∫§T ƒê∆Ø·ª¢C PH√âP S·ª¨ D·ª§NG:
- Th√¥ng tin trong ph·∫ßn "TH√îNG TIN THAM KH·∫¢O T·ª™ C∆† S·ªû KI·∫æN TH·ª®C" b√™n d∆∞·ªõi.
- Kh√¥ng s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i ho·∫∑c suy ƒëo√°n v∆∞·ª£t qu√° d·ªØ li·ªáu ƒë√£ cho.

TH√îNG TIN THAM KH·∫¢O T·ª™ C∆† S·ªû KI·∫æN TH·ª®C:
{context}

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. ƒê·ªçc k·ªπ c√¢u h·ªèi v√† T·∫§T C·∫¢ c√°c ph∆∞∆°ng √°n tr·∫£ l·ªùi.
2. Lo·∫°i tr·ª´ c√°c ph∆∞∆°ng √°n m√¢u thu·∫´n, kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£, ho·∫∑c kh√¥ng kh·ªõp v·ªõi d·ªØ li·ªáu tham kh·∫£o.
3. Ch·ªâ ch·ªçn ph∆∞∆°ng √°n c√≥ b·∫±ng ch·ª©ng ph√π h·ª£p v√† tr·ª±c ti·∫øp nh·∫•t t·ª´ d·ªØ li·ªáu.
4. N·∫øu nhi·ªÅu ph∆∞∆°ng √°n g·∫ßn ƒë√∫ng, ch·ªçn ph∆∞∆°ng √°n CH√çNH X√ÅC NH·∫§T, C·ª§ TH·ªÇ NH·∫§T.
5. KH√îNG suy lu·∫≠n v∆∞·ª£t qu√° d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p.

ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
- Ch·ªâ tr·∫£ l·ªùi DUY NH·∫§T M·ªòT K√ù T·ª∞ IN HOA: A, B, C, D, ...
- KH√îNG gi·∫£i th√≠ch.
- KH√îNG th√™m k√Ω t·ª±, d·∫•u ch·∫•m, ho·∫∑c vƒÉn b·∫£n n√†o kh√°c.

L∆ØU √ù QUAN TR·ªåNG:
- N·∫øu th√¥ng tin kh√¥ng ƒë·∫ßy ƒë·ªß, h√£y ch·ªçn ph∆∞∆°ng √°n ph√π h·ª£p nh·∫•t v·ªõi d·ªØ li·ªáu hi·ªán c√≥, KH√îNG b·ªè tr·ªëng.
"""

    else:
        system_content = """B·∫°n l√† h·ªá th·ªëng tr·∫£ l·ªùi c√¢u h·ªèi tr·∫Øc nghi·ªám.

H∆Ø·ªöNG D·∫™N:
1. ƒê·ªçc k·ªπ c√¢u h·ªèi v√† t·∫•t c·∫£ l·ª±a ch·ªçn
2. TR·∫¢ L·ªúI CH·ªà B·∫∞NG M·ªòT K√ù T·ª∞: A, B, C, ho·∫∑c D
3. KH√îNG gi·∫£i th√≠ch, KH√îNG th√™m vƒÉn b·∫£n
4. N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y ch·ªçn ƒë√°p √°n c√≥ v·∫ª h·ª£p l√Ω nh·∫•t

V√≠ d·ª• tr·∫£ l·ªùi ƒë√∫ng: C"""
    
    user_content = f"C√¢u h·ªèi: {question}\n\nL·ª±a ch·ªçn:\n{choices}"
    
    payload = {
        'model': "vnptai_hackathon_small",
        'messages': [
            {'role': 'system', 'content': system_content},
            {'role': 'user', 'content': user_content}
        ],
        'temperature': 0.1,
        'top_p': 0.9,
        'top_k': 20,
        'n': 1,
        'max_completion_tokens': 1,
    }
    
    # Step 3: Call API
    try:
        result = call_api_with_retry(payload, max_retries=CONFIG['max_retries'])
        
        if result and "choices" in result:
            answer = result["choices"][0]["message"]["content"].strip()
            
            # Debug: show raw response
            print(f"   ü§ñ Raw response: '{answer}'")
            
            # Clean the answer
            if answer:
                # Take first character and convert to uppercase
                clean_answer = answer[0].upper() if answer[0].isalpha() else ""
                
                # if clean_answer in ['A', 'B', 'C', 'D']:
                if clean_answer.isalpha() and clean_answer.isupper():
                    return clean_answer
                elif answer[0].isdigit():
                    num = int(answer[0])
                    if 1 <= num:
                        return chr(65 + num)  # 0->A, 1->B, etc. c·∫ßn ƒë·ªÉ √Ω
    
    except Exception as e:
        print(f"   ‚ùå API error: {e}")
        # Wait a bit longer on error
        time.sleep(2)
    
    # Fallback - return first option
    return "A"

# =========================================================
# LOAD EXISTING PROGRESS
# =========================================================
def load_existing_progress():
    """Load already processed questions"""
    processed = set()
    
    if os.path.exists(CONFIG['output_path']):
        with open(CONFIG['output_path'], 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            try:
                header = next(reader)  # Skip header
                for row in reader:
                    if row and len(row) >= 1:
                        processed.add(row[0])
            except StopIteration:
                pass
    
    return processed, len(processed)

# =========================================================
# QUOTA MANAGEMENT
# =========================================================
class QuotaManager:
    def __init__(self, max_per_hour=60, max_per_day=1000):
        self.max_per_hour = max_per_hour
        self.max_per_day = max_per_day
        self.hourly_requests = []
        self.daily_requests = []
        self.total_requests = 0
        self.current_hour = datetime.now().hour
        
    def can_make_request(self):
        """Check if we can make a request"""
        now = time.time()
        
        # Reset if hour changed
        now_hour = datetime.now().hour
        if now_hour != self.current_hour:
            self.hourly_requests = []
            self.current_hour = now_hour
        
        # Remove old requests
        self.hourly_requests = [t for t in self.hourly_requests if now - t < 3600]
        self.daily_requests = [t for t in self.daily_requests if now - t < 86400]
        
        # Check limits
        if len(self.daily_requests) >= self.max_per_day:
            return False
        
        if len(self.hourly_requests) >= self.max_per_hour:
            return False
        
        return True
    
    def record_request(self):
        """Record that a request was made"""
        now = time.time()
        self.hourly_requests.append(now)
        self.daily_requests.append(now)
        self.total_requests += 1
    
    def wait_if_needed(self):
        """Wait if quota limits are reached"""
        if not self.can_make_request():
            # Check which limit is reached
            now = time.time()
            self.hourly_requests = [t for t in self.hourly_requests if now - t < 3600]
            self.daily_requests = [t for t in self.daily_requests if now - t < 86400]
            
            if len(self.hourly_requests) >= self.max_per_hour:
                # Calculate wait time for hourly limit
                oldest = min(self.hourly_requests)
                wait_time = 3600 - (now - oldest) + 5
                print(f"   ‚è≥ Hourly limit reached ({self.max_per_hour}/hour), waiting {wait_time/60:.1f} minutes...")
                time.sleep(wait_time)
            
            if len(self.daily_requests) >= self.max_per_day:
                print("‚ùå Daily limit reached (1000/day). Stopping.")
                return False
        
        return True
    
    def get_stats(self):
        """Get current statistics"""
        now = time.time()
        hourly_count = len([t for t in self.hourly_requests if now - t < 3600])
        daily_count = len([t for t in self.daily_requests if now - t < 86400])
        
        return {
            'hourly': hourly_count,
            'max_hourly': self.max_per_hour,
            'daily': daily_count,
            'max_daily': self.max_per_day,
            'total': self.total_requests
        }

quota_manager = QuotaManager(
    max_per_hour=CONFIG['max_requests_per_hour'],
    max_per_day=CONFIG['max_requests_per_day']
)

# =========================================================
# MAIN EXECUTION
# =========================================================
def main():
    print("\n" + "="*70)
    print("üöÄ VNPT RAG + VNPT AI System")
    print("="*70)
    
    # Load progress
    processed_qids, processed_count = load_existing_progress()
    total = len(dataset)
    
    print(f"üìä Dataset: {total} questions total")
    print(f"üìà Progress: {processed_count} already processed")
    print(f"‚öôÔ∏è  Mode: {'RAG + LLM' if CONFIG['use_rag'] else 'LLM only'}")
    print(f"ü§ñ Model: vnptai_hackathon_small")
    print(f"‚è∞ Start time: {datetime.now().strftime('%H:%M:%S')}")
    print("="*70 + "\n")
    
    # Check if we've already processed everything
    if processed_count >= total:
        print("‚úÖ All questions have already been processed!")
        return
    
    # Open output file
    file_mode = 'a' if processed_count > 0 else 'w'
    with open(CONFIG['output_path'], file_mode, newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        
        # Write header if new file
        if file_mode == 'w':
            writer.writerow(['qid', 'answer'])
        
        # Process questions
        for idx, item in enumerate(tqdm(dataset, desc="Processing", unit="q")):
            qid = item['qid']
            
            # Skip if already processed
            if qid in processed_qids:
                continue
            
            question = item['question']
            choices = "\n".join(item['choices'])
            
            # Display current question
            print(f"\n[{idx+1}/{total}] QID: {qid}")
            if len(question) > 80:
                print(f"   ‚ùì {question[:80]}...")
            else:
                print(f"   ‚ùì {question}")
            
            # Check quota before making request
            if not quota_manager.wait_if_needed():
                break
            
            # Get prediction
            try:
                answer = predict_answer(question, choices)
                print(f"   ‚úÖ Answer: {answer}")
                
                # Record the API request
                quota_manager.record_request()
                
                # Write result
                writer.writerow([qid, answer])
                f.flush()  # Ensure immediate write
                
                # Add to processed set
                processed_qids.add(qid)
                
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
                # Write fallback answer
                writer.writerow([qid, 'A'])
                f.flush()
                processed_qids.add(qid)
            
            # Show quota stats
            stats = quota_manager.get_stats()
            print(f"   üìä Quota: {stats['hourly']}/{stats['max_hourly']} per hour, "
                  f"{stats['daily']}/{stats['max_daily']} per day")
            
            # Delay between requests
            time.sleep(CONFIG['request_delay'])
    
    # Final summary
    print("\n" + "="*70)
    print("üéâ PROCESSING COMPLETE!")
    print("="*70)
    
    final_stats = quota_manager.get_stats()
    print(f"üìä Statistics:")
    print(f"   Total requests made: {final_stats['total']}")
    print(f"   Questions processed: {len(processed_qids)}/{total}")
    print(f"   Hourly usage: {final_stats['hourly']}/{final_stats['max_hourly']}")
    print(f"   Daily usage: {final_stats['daily']}/{final_stats['max_daily']}")
    
    if CONFIG['use_rag'] and rag_system and rag_system.embedder:
        embed_usage = rag_system.embedder.get_usage()
        print(f"   Embedding API usage: {embed_usage['used']}/{embed_usage['total']}")
    
    print(f"üìÅ Results saved to: {CONFIG['output_path']}")
    print("="*70)

# =========================================================
# RUN MAIN FUNCTION
# =========================================================
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Process interrupted by user. Progress has been saved.")
        print(f"üìÅ You can resume by running the script again.")
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()